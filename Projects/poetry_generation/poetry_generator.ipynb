{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a8f615",
   "metadata": {},
   "source": [
    "# Poetry Generation with LSTM & GRU (Keras)\n",
    "This notebook explores how to build and train a Recurrent Neural Network (RNN) using LSTM and GRU layers to generate poetry. \n",
    "\n",
    "Models are trained on a custom dataset of poems and learns to predict and generate poetic lines based on input text.\n",
    "\n",
    "- Framework: TensorFlow / Keras  \n",
    "- Architecture: Word-level LSTM / GRU \n",
    "- Dataset: CSV file (`kaggle_poem_dataset.csv`)   https://www.kaggle.com/datasets/johnhallman/complete-poetryfoundationorg-dataset\n",
    "- Goal: Generate poetry using AI with adjustable creativity (temperature sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GRU, Attention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88067099",
   "metadata": {},
   "source": [
    "## Load and clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5550349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (15652, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Poetry Foundation ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wendy Videlock</td>\n",
       "      <td>!</td>\n",
       "      <td>55489</td>\n",
       "      <td>Dear Writers, I’m compiling the first in what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hailey Leithauser</td>\n",
       "      <td>0</td>\n",
       "      <td>41729</td>\n",
       "      <td>Philosophic\\nin its complex, ovoid emptiness,\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jody Gladding</td>\n",
       "      <td>1-800-FEAR</td>\n",
       "      <td>57135</td>\n",
       "      <td>We'd  like  to  talk  with  you  about  fear t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Joseph Brodsky</td>\n",
       "      <td>1 January 1965</td>\n",
       "      <td>56736</td>\n",
       "      <td>The Wise Men will unlearn your name.\\nAbove yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ted Berrigan</td>\n",
       "      <td>3 Pages</td>\n",
       "      <td>51624</td>\n",
       "      <td>For Jack Collom\\n10 Things I do Every Day\\n\\np...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                            Content\n",
       "0           0  ...  Dear Writers, I’m compiling the first in what ...\n",
       "1           1  ...  Philosophic\\nin its complex, ovoid emptiness,\\...\n",
       "2           2  ...  We'd  like  to  talk  with  you  about  fear t...\n",
       "3           3  ...  The Wise Men will unlearn your name.\\nAbove yo...\n",
       "4           4  ...  For Jack Collom\\n10 Things I do Every Day\\n\\np...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data using pandas library\n",
    "data = pd.read_csv(\"kaggle_poem_dataset.csv\", encoding='utf-8', keep_default_na=False, engine='python')\n",
    "print(f\"Data shape {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9315363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = data[1:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2bab51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows without actual poems\n",
    "small_data = small_data.dropna(subset=[\"Content\"])\n",
    "\n",
    "# Combine all poems into one large string\n",
    "poems = \"\\n\".join(small_data[\"Content\"].astype(str).tolist()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22919654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "philosophic\n",
      "in its complex, ovoid emptiness,\n",
      "a skillful pundit coined it as a sort\n",
      "of stopgap doorstop for those\n",
      "quaint equations\n",
      "\n",
      "romans never\n",
      "dreamt of. in form completely clever\n",
      "and discrete—a mirror come unsilvered,\n",
      "loose watch face without the works,\n",
      "a hollowed globe\n",
      "\n",
      "from tip to toe\n",
      "unbroken, it evades the grappling\n",
      "hooks of mass, tilts the thin rim of no thing,\n",
      "remains embryonic sum,\n",
      "non-cogito.\n",
      "we'd  like  to  talk  with  you  about  fear they  said  so\n",
      "many  people  live  in  fear  thes\n"
     ]
    }
   ],
   "source": [
    "print(poems[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8427997",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9167882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 5000\n",
      "Total training sequences: 955739\n"
     ]
    }
   ],
   "source": [
    "# create instance of tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "# fit tokenizer to current text\n",
    "tokenizer.fit_on_texts([poems])\n",
    "\n",
    "total_words = tokenizer.num_words\n",
    "print(f\"Total unique words: {total_words}\")\n",
    "\n",
    "# Generate input sequences using n-gram approach\n",
    "input_sequences = []\n",
    "for line in poems.split(\"\\n\"):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "print(f\"Total training sequences: {len(input_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a9baba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[415, 4402],\n",
       " [415, 4402, 213],\n",
       " [415, 4402, 213, 1],\n",
       " [415, 4402, 213, 1, 115],\n",
       " [415, 4402, 213, 1, 115, 6],\n",
       " [415, 4402, 213, 1, 115, 6, 37],\n",
       " [415, 4402, 213, 1, 115, 6, 37, 7],\n",
       " [415, 4402, 213, 1, 115, 6, 37, 7, 416],\n",
       " [9, 4],\n",
       " [9, 4, 3148]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample content of input_sequences\n",
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79ba6d",
   "metadata": {},
   "source": [
    "## Pad Sequences and Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d73ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all lines at a cap of 50 words\n",
    "max_seq_len = 50\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n",
    "\n",
    "# x contains all words except  the last word (to be generated)\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1] # word to be generated for each line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037cf0a",
   "metadata": {},
   "source": [
    "## Build and Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffec58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 49, 100)           500000    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 49, 256)           365568    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 49, 256)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5000)              1285000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,675,880\n",
      "Trainable params: 2,675,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "11787/11787 [==============================] - 286s 24ms/step - loss: 6.3105 - accuracy: 0.0906\n",
      "Epoch 2/50\n",
      "11787/11787 [==============================] - 305s 26ms/step - loss: 5.9839 - accuracy: 0.1077\n",
      "Epoch 3/50\n",
      "11787/11787 [==============================] - 273s 23ms/step - loss: 5.8501 - accuracy: 0.1138\n",
      "Epoch 4/50\n",
      "11787/11787 [==============================] - 441s 37ms/step - loss: 5.7558 - accuracy: 0.1178\n",
      "Epoch 5/50\n",
      "11787/11787 [==============================] - 207s 18ms/step - loss: 5.6819 - accuracy: 0.1210\n",
      "Epoch 6/50\n",
      "11787/11787 [==============================] - 291s 25ms/step - loss: 5.6231 - accuracy: 0.1236\n",
      "Epoch 7/50\n",
      "11787/11787 [==============================] - 424s 36ms/step - loss: 5.5695 - accuracy: 0.1256\n",
      "Epoch 8/50\n",
      "11787/11787 [==============================] - 378s 32ms/step - loss: 5.5209 - accuracy: 0.1278\n",
      "Epoch 9/50\n",
      "11787/11787 [==============================] - 325s 28ms/step - loss: 5.4768 - accuracy: 0.1296\n",
      "Epoch 10/50\n",
      "11787/11787 [==============================] - 345s 29ms/step - loss: 5.4336 - accuracy: 0.1312\n",
      "Epoch 11/50\n",
      "11787/11787 [==============================] - 322s 27ms/step - loss: 5.3935 - accuracy: 0.1335\n",
      "Epoch 12/50\n",
      "11787/11787 [==============================] - 356s 30ms/step - loss: 5.3567 - accuracy: 0.1356\n",
      "Epoch 13/50\n",
      "11787/11787 [==============================] - 384s 33ms/step - loss: 5.3203 - accuracy: 0.1368\n",
      "Epoch 14/50\n",
      "11787/11787 [==============================] - 287s 24ms/step - loss: 5.2868 - accuracy: 0.1381\n",
      "Epoch 15/50\n",
      "11787/11787 [==============================] - 112s 9ms/step - loss: 5.2507 - accuracy: 0.1401\n",
      "Epoch 16/50\n",
      "11787/11787 [==============================] - 116s 10ms/step - loss: 5.2215 - accuracy: 0.1418\n",
      "Epoch 17/50\n",
      "11787/11787 [==============================] - 112s 9ms/step - loss: 5.1937 - accuracy: 0.1436\n",
      "Epoch 18/50\n",
      "11787/11787 [==============================] - 364s 31ms/step - loss: 5.1660 - accuracy: 0.1438\n",
      "Epoch 19/50\n",
      "11787/11787 [==============================] - 5410s 459ms/step - loss: 5.1382 - accuracy: 0.1455\n",
      "Epoch 20/50\n",
      "11787/11787 [==============================] - 122s 10ms/step - loss: 5.1134 - accuracy: 0.1475\n",
      "Epoch 21/50\n",
      " 5528/11787 [=============>................] - ETA: 1:01 - loss: 5.0375 - accuracy: 0.1508"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        Embedding(total_words, 100, input_length=max_seq_len - 1),\n",
    "        LSTM(256, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(256),\n",
    "        Dropout(0.2),\n",
    "        Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(monitor='loss',patience = 8)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, epochs=50, verbose=1, callbacks=[early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8f0e0",
   "metadata": {},
   "source": [
    "##### lstm model took too much time to train locally and ultimately got interrupted. training on colab did work, but results were not good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3aaa3e",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7cf7d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 100)           500000    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 49, 256)           274944    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 49, 256)           0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 256)               394752    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5000)              1285000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,454,696\n",
      "Trainable params: 2,454,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "11787/11787 [==============================] - 198s 15ms/step - loss: 6.3895 - accuracy: 0.0894\n",
      "Epoch 2/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.9894 - accuracy: 0.1080\n",
      "Epoch 3/50\n",
      "11787/11787 [==============================] - 128s 11ms/step - loss: 5.8745 - accuracy: 0.1136\n",
      "Epoch 4/50\n",
      "11787/11787 [==============================] - 122s 10ms/step - loss: 5.8038 - accuracy: 0.1164\n",
      "Epoch 5/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.7549 - accuracy: 0.1182\n",
      "Epoch 6/50\n",
      "11787/11787 [==============================] - 117s 10ms/step - loss: 5.7167 - accuracy: 0.1198\n",
      "Epoch 7/50\n",
      "11787/11787 [==============================] - 116s 10ms/step - loss: 5.6863 - accuracy: 0.1207\n",
      "Epoch 8/50\n",
      "11787/11787 [==============================] - 115s 10ms/step - loss: 5.6598 - accuracy: 0.1217\n",
      "Epoch 9/50\n",
      "11787/11787 [==============================] - 123s 10ms/step - loss: 5.6367 - accuracy: 0.1235\n",
      "Epoch 10/50\n",
      "11787/11787 [==============================] - 124s 10ms/step - loss: 5.6147 - accuracy: 0.1245\n",
      "Epoch 11/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.5977 - accuracy: 0.1245\n",
      "Epoch 12/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.5830 - accuracy: 0.1261\n",
      "Epoch 13/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.5681 - accuracy: 0.1262\n",
      "Epoch 14/50\n",
      "11787/11787 [==============================] - 120s 10ms/step - loss: 5.5564 - accuracy: 0.1269\n",
      "Epoch 15/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.5450 - accuracy: 0.1275\n",
      "Epoch 16/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.5317 - accuracy: 0.1281\n",
      "Epoch 17/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.5195 - accuracy: 0.1291\n",
      "Epoch 18/50\n",
      "11787/11787 [==============================] - 120s 10ms/step - loss: 5.5105 - accuracy: 0.1294\n",
      "Epoch 19/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.5019 - accuracy: 0.1301\n",
      "Epoch 20/50\n",
      "11787/11787 [==============================] - 120s 10ms/step - loss: 5.4908 - accuracy: 0.1303\n",
      "Epoch 21/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.4842 - accuracy: 0.1310\n",
      "Epoch 22/50\n",
      "11787/11787 [==============================] - 120s 10ms/step - loss: 5.4757 - accuracy: 0.1315\n",
      "Epoch 23/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.4681 - accuracy: 0.1320\n",
      "Epoch 24/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.4616 - accuracy: 0.1323\n",
      "Epoch 25/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.4575 - accuracy: 0.1324\n",
      "Epoch 26/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.4530 - accuracy: 0.1322\n",
      "Epoch 27/50\n",
      "11787/11787 [==============================] - 120s 10ms/step - loss: 5.4451 - accuracy: 0.1330\n",
      "Epoch 28/50\n",
      "11787/11787 [==============================] - 124s 11ms/step - loss: 5.4405 - accuracy: 0.1328\n",
      "Epoch 29/50\n",
      "11787/11787 [==============================] - 123s 10ms/step - loss: 5.4364 - accuracy: 0.1334\n",
      "Epoch 30/50\n",
      "11787/11787 [==============================] - 120s 10ms/step - loss: 5.4304 - accuracy: 0.1336\n",
      "Epoch 31/50\n",
      "11787/11787 [==============================] - 120s 10ms/step - loss: 5.4294 - accuracy: 0.1334\n",
      "Epoch 32/50\n",
      "11787/11787 [==============================] - 122s 10ms/step - loss: 5.4248 - accuracy: 0.1338\n",
      "Epoch 33/50\n",
      "11787/11787 [==============================] - 121s 10ms/step - loss: 5.4214 - accuracy: 0.1345\n",
      "Epoch 34/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.4198 - accuracy: 0.1342\n",
      "Epoch 35/50\n",
      "11787/11787 [==============================] - 117s 10ms/step - loss: 5.4170 - accuracy: 0.1343\n",
      "Epoch 36/50\n",
      "11787/11787 [==============================] - 118s 10ms/step - loss: 5.4146 - accuracy: 0.1348\n",
      "Epoch 37/50\n",
      "11787/11787 [==============================] - 324s 27ms/step - loss: 5.4108 - accuracy: 0.1348\n",
      "Epoch 38/50\n",
      "11787/11787 [==============================] - 465s 39ms/step - loss: 5.4090 - accuracy: 0.1350\n",
      "Epoch 39/50\n",
      "11787/11787 [==============================] - 315s 27ms/step - loss: 5.4083 - accuracy: 0.1346\n",
      "Epoch 40/50\n",
      "11787/11787 [==============================] - 115s 10ms/step - loss: 5.4052 - accuracy: 0.1351\n",
      "Epoch 41/50\n",
      "11787/11787 [==============================] - 117s 10ms/step - loss: 5.4018 - accuracy: 0.1357\n",
      "Epoch 42/50\n",
      "11787/11787 [==============================] - 126s 11ms/step - loss: 5.4005 - accuracy: 0.1357\n",
      "Epoch 43/50\n",
      "11787/11787 [==============================] - 115s 10ms/step - loss: 5.3989 - accuracy: 0.1352\n",
      "Epoch 44/50\n",
      "11787/11787 [==============================] - 114s 10ms/step - loss: 5.3976 - accuracy: 0.1360\n",
      "Epoch 45/50\n",
      "11787/11787 [==============================] - 116s 10ms/step - loss: 5.3963 - accuracy: 0.1357\n",
      "Epoch 46/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.3947 - accuracy: 0.1354\n",
      "Epoch 47/50\n",
      "11787/11787 [==============================] - 117s 10ms/step - loss: 5.3913 - accuracy: 0.1358\n",
      "Epoch 48/50\n",
      "11787/11787 [==============================] - 119s 10ms/step - loss: 5.3915 - accuracy: 0.1360\n",
      "Epoch 49/50\n",
      "11787/11787 [==============================] - 120s 10ms/step - loss: 5.3879 - accuracy: 0.1359\n",
      "Epoch 50/50\n",
      "11787/11787 [==============================] - 117s 10ms/step - loss: 5.3871 - accuracy: 0.1365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19db6c80880>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_seq_len - 1),\n",
    "    GRU(256, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    GRU(256),\n",
    "    Dropout(0.2),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(monitor='loss',patience = 8)\n",
    "\n",
    "gru_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gru_model.summary()\n",
    "\n",
    "gru_model.fit(X, y, epochs=50, verbose=1, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbe35457",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.save(\"poetry_gru_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6418ae",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb32adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defien funcitons to generate text using trained model\n",
    "def sample_with_temperature(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-10) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(preds), p=preds)\n",
    "\n",
    "def generate_poem(seed_text, model, next_words=30, temperature=1.0):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_len - 1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_index = sample_with_temperature(predicted, temperature)\n",
    "        output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5abcd0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the blue sky the roof of the world is a little in the of the sun in the air and the sun is\n"
     ]
    }
   ],
   "source": [
    "print(generate_poem(\"the blue sky\", model=gru_model, next_words=20, temperature=0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a777b",
   "metadata": {},
   "source": [
    "#### gru_model did generate some text, however it isn't performing well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f2aaa1",
   "metadata": {},
   "source": [
    "## GRU with attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62d2ec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 49)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 49, 100)      500000      ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " gru_22 (GRU)                   (None, 49, 256)      274944      ['embedding_11[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 49, 256)      0           ['gru_22[0][0]']                 \n",
      "                                                                                                  \n",
      " gru_23 (GRU)                   (None, 49, 256)      394752      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " attention_10 (Attention)       (None, 49, 256)      0           ['gru_23[0][0]',                 \n",
      "                                                                  'gru_23[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 256)         0           ['attention_10[0][0]']           \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 5000)         1285000     ['global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,454,696\n",
      "Trainable params: 2,454,696\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_seq_len-1,))\n",
    "x = Embedding(total_words, 100)(input)\n",
    "x = GRU(256, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = GRU(256, return_sequences=True)(x)\n",
    "attn_output = Attention()([x, x])\n",
    "x = GlobalAveragePooling1D()(attn_output)\n",
    "x = Dense(total_words, activation='softmax')(x)\n",
    "gru_model2 = Model(inputs=input, outputs=x)\n",
    "gru_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0503d28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29867/29867 [==============================] - 709s 24ms/step - loss: 6.4619 - accuracy: 0.0779\n",
      "Epoch 2/50\n",
      "29867/29867 [==============================] - 551s 18ms/step - loss: 6.1691 - accuracy: 0.0924\n",
      "Epoch 3/50\n",
      "29867/29867 [==============================] - 320s 11ms/step - loss: 5.9547 - accuracy: 0.1063\n",
      "Epoch 4/50\n",
      "29867/29867 [==============================] - 423s 14ms/step - loss: 5.8611 - accuracy: 0.1117\n",
      "Epoch 5/50\n",
      "29867/29867 [==============================] - 718s 24ms/step - loss: 5.9114 - accuracy: 0.1073\n",
      "Epoch 6/50\n",
      "29867/29867 [==============================] - 950s 32ms/step - loss: 5.8243 - accuracy: 0.1128\n",
      "Epoch 7/50\n",
      "29867/29867 [==============================] - 300s 10ms/step - loss: 5.9445 - accuracy: 0.1045\n",
      "Epoch 8/50\n",
      "29867/29867 [==============================] - 799s 27ms/step - loss: 6.0473 - accuracy: 0.0981\n",
      "Epoch 9/50\n",
      "29867/29867 [==============================] - 542s 18ms/step - loss: 6.0630 - accuracy: 0.0975\n",
      "Epoch 10/50\n",
      " 6821/29867 [=====>........................] - ETA: 4:03 - loss: 5.9531 - accuracy: 0.1013"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m early_stopping_monitor \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m gru_model2\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m \u001b[43mgru_model2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_monitor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\nkola\\anaconda3\\envs\\py3-TF2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='loss',patience = 5)\n",
    "\n",
    "gru_model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "gru_model2.fit(X, y, epochs=50, verbose=1, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51127061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d482b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becec71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec3997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
